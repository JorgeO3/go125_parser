# Go 1.25 Parser

Parser completo para el lenguaje Go 1.25 implementado en Rust, diseÃ±ado con principios de ingenierÃ­a de compiladores modernos.

## Ãndice

- [VisiÃ³n General](#visiÃ³n-general)
- [Arquitectura del Compilador](#arquitectura-del-compilador)
- [Sistema de AnÃ¡lisis LÃ©xico (Lexer)](#sistema-de-anÃ¡lisis-lÃ©xico-lexer)
- [Sistema de AnÃ¡lisis SintÃ¡ctico (Parser)](#sistema-de-anÃ¡lisis-sintÃ¡ctico-parser)
- [Ãrbol de Sintaxis Abstracta (AST)](#Ã¡rbol-de-sintaxis-abstracta-ast)
- [EspecificaciÃ³n Go 1.25](#especificaciÃ³n-go-125)
- [SÃ­mbolos No Terminales Soportados](#sÃ­mbolos-no-terminales-soportados)
- [SÃ­mbolos Terminales Soportados](#sÃ­mbolos-terminales-soportados)
- [Dependencias](#dependencias)
- [Uso](#uso)
- [Testing y ValidaciÃ³n](#testing-y-validaciÃ³n)

---

## VisiÃ³n General

Este proyecto implementa un **frontend de compilador** completo para Go 1.25 que procesa cÃ³digo fuente Go y produce un Ãrbol de Sintaxis Abstracta (AST) tipado y validado. El sistema estÃ¡ diseÃ±ado siguiendo el modelo clÃ¡sico de compilador en mÃºltiples fases:

```
CÃ³digo Fuente â†’ Lexer â†’ Stream de Tokens â†’ Parser â†’ AST â†’ [AnÃ¡lisis SemÃ¡ntico]
```

### CaracterÃ­sticas Principales

- **AnÃ¡lisis LÃ©xico**: TokenizaciÃ³n completa con soporte para inserciÃ³n automÃ¡tica de punto y coma (`;`)
- **AnÃ¡lisis SintÃ¡ctico**: Parser LR(1) generado con LALRPOP que reconoce la gramÃ¡tica completa de Go
- **AST Optimizado**: RepresentaciÃ³n eficiente en memoria usando arenas y referencias tipadas
- **RecuperaciÃ³n de Errores**: Sistema robusto de diagnÃ³sticos con soporte para error recovery
- **Conformidad con Spec**: ImplementaciÃ³n fiel a la especificaciÃ³n oficial de Go 1.25

---

## Arquitectura del Compilador

### Fases del Frontend

El compilador estÃ¡ estructurado en tres fases principales:

#### 1. **AnÃ¡lisis LÃ©xico (Lexical Analysis)**
   - **Input**: String UTF-8 con cÃ³digo fuente Go
   - **Output**: Stream de tokens con posiciones
   - **Responsabilidad**: Reconocimiento de patrones lÃ©xicos y clasificaciÃ³n de tokens

#### 2. **AnÃ¡lisis SintÃ¡ctico (Syntactic Analysis)**
   - **Input**: Stream de tokens del lexer
   - **Output**: Ãrbol de Sintaxis Abstracta (AST)
   - **Responsabilidad**: ValidaciÃ³n de la estructura gramatical del programa

#### 3. **ConstrucciÃ³n del AST (Abstract Syntax Tree)**
   - **Input**: Acciones semÃ¡nticas del parser
   - **Output**: Estructura de datos en memoria
   - **Responsabilidad**: RepresentaciÃ³n intermedia para anÃ¡lisis posteriores

### SeparaciÃ³n de Concerns

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CÃ³digo Fuente Go                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LEXER (crates/parser/src/lexer.rs)                         â”‚
â”‚  â€¢ Escaneo de caracteres (Logos)                            â”‚
â”‚  â€¢ TokenizaciÃ³n                                             â”‚
â”‚  â€¢ InserciÃ³n automÃ¡tica de ';'                              â”‚
â”‚  â€¢ Manejo de comentarios                                    â”‚
â”‚  â€¢ ValidaciÃ³n de literales (nÃºmeros, strings, runes)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ Vec<(usize, Tok<'src>, usize)>
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PARSER (crates/parser/src/parser.lalrpop)                  â”‚
â”‚  â€¢ Parser LR(1) generado por LALRPOP                        â”‚
â”‚  â€¢ Reconocimiento de gramÃ¡tica EBNF                         â”‚
â”‚  â€¢ ConstrucciÃ³n dirigida por sintaxis                       â”‚
â”‚  â€¢ Error recovery con nodos Bad                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ AST
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AST (crates/parser/src/ast.rs)                             â”‚
â”‚  â€¢ Arena allocation para nodos                              â”‚
â”‚  â€¢ Tablas laterales de spans                                â”‚
â”‚  â€¢ Symbol interning                                         â”‚
â”‚  â€¢ Referencias tipadas (Id<T>, ListRef<T>)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Sistema de AnÃ¡lisis LÃ©xico (Lexer)

**Archivo**: [`crates/parser/src/lexer.rs`](crates/parser/src/lexer.rs)

### DescripciÃ³n

El lexer es la primera fase del compilador y se encarga de transformar el flujo de caracteres del cÃ³digo fuente en una secuencia de tokens clasificados. Utiliza el crate **Logos** para generar un escÃ¡ner de alto rendimiento basado en autÃ³matas finitos deterministas (DFA).

### CaracterÃ­sticas TÃ©cnicas

#### 1. **TokenizaciÃ³n Zero-Copy**
```rust
pub enum Tok<'input> {
    Ident(&'input str),      // Referencias directas al buffer fuente
    IntLit(&'input str),
    StringLit(&'input str),
    // ...
}
```

- Los tokens literales mantienen referencias al buffer original (`&'input str`)
- No hay copias de strings durante el escaneo
- Reduce significativamente el overhead de memoria

#### 2. **InserciÃ³n AutomÃ¡tica de Punto y Coma**

Go tiene reglas especÃ­ficas para la inserciÃ³n implÃ­cita de `;`:

**Regla**: Se inserta `;` antes de una nueva lÃ­nea si el token anterior puede terminar una sentencia.

```rust
const SEMI_INSERT_TABLE: [bool; N] = [...];

impl RawTok {
    const fn can_insert_semicolon(self) -> bool {
        SEMI_INSERT_TABLE[self as usize]
    }
}
```

Tokens que permiten inserciÃ³n de `;`:
- Identificadores y literales: `ident`, `int_lit`, `float_lit`, `imag_lit`, `rune_lit`, `string_lit`
- Keywords de tÃ©rmino: `break`, `continue`, `fallthrough`, `return`
- Operadores: `++`, `--`, `)`, `]`, `}`

#### 3. **ClasificaciÃ³n de Literales NumÃ©ricos**

El lexer realiza anÃ¡lisis sofisticado de nÃºmeros con soporte para:

- **Enteros**: `42`, `0x2A`, `0o52`, `0b101010`
- **Flotantes**: `3.14`, `1e10`, `0x1.8p3`
- **Imaginarios**: `3.14i`, `1e10i`
- **Underscores**: `1_000_000`, `0b1111_0000`

```rust
// ValidaciÃ³n en tiempo de escaneo
fn is_decimal_digits_with_underscores(bytes: &[u8]) -> bool {
    // Verifica que underscores estÃ©n entre dÃ­gitos
}
```

#### 4. **Manejo de Strings y Runes**

- **Strings interpretados**: `"hello\n"` con soporte para escapes Unicode (`\u`, `\U`, `\x`)
- **Raw strings**: `` `hello\n` `` sin procesamiento de escapes
- **Runes**: `'a'`, `'\n'`, `'\u0041'`

#### 5. **Comentarios**

- **LÃ­nea**: `// comentario hasta EOL`
- **Bloque**: `/* comentario multilÃ­nea */`
  - El lexer detecta si hay `\n` dentro del comentario para inserciÃ³n de `;`

### Estado del Lexer

```rust
struct LexExtras {
    block_nl_off: u32,  // Offset a newline en comentario de bloque
    num_info: u8,       // ClasificaciÃ³n de nÃºmero: 0=invÃ¡lido, 1=int, 2=float
}
```

### Manejo de Errores

El lexer produce diagnÃ³sticos estructurados:

```rust
pub enum LexErrorKind {
    InvalidToken,           // Token no reconocido
    InvalidNumber,          // Literal numÃ©rico malformado
    InvalidEscape,          // Secuencia de escape invÃ¡lida
    UnterminatedString,     // String sin cerrar
    UnterminatedComment,    // Comentario de bloque sin */
}
```

---

## Sistema de AnÃ¡lisis SintÃ¡ctico (Parser)

**Archivo**: [`crates/parser/src/parser.lalrpop`](crates/parser/src/parser.lalrpop)

### DescripciÃ³n

El parser implementa un analizador sintÃ¡ctico **LR(1)** generado automÃ¡ticamente por LALRPOP a partir de una gramÃ¡tica EBNF. Este tipo de parser es determinista, eficiente (O(n)) y maneja precedencia de operadores sin ambigÃ¼edades.

### TecnologÃ­a: LALRPOP

**LALRPOP** (LR(1) Parser Generator) genera cÃ³digo Rust a partir de definiciones gramaticales:

```lalrpop
grammar<'input>(arena: &mut AstArena, interner: &mut Interner);

pub SourceFile: ast::SourceFile = {
    "package" <name:Ident> ";" <imports:ImportDecls> <decls:TopLevelDecls> => {
        ast::SourceFile { name, decls, ... }
    }
};
```

### CaracterÃ­sticas del Parser

#### 1. **ConstrucciÃ³n Dirigida por Sintaxis (Syntax-Directed Translation)**

Cada producciÃ³n gramatical tiene una acciÃ³n semÃ¡ntica que construye nodos del AST:

```lalrpop
FuncDecl: ast::FuncDeclId = {
    <s:@L> "func" <name:Ident> <sig:Signature> <body:Block> <e:@R> => {
        arena.funcs.alloc(ast::FuncDecl {
            func_pos: Span::new(s, s + 4),
            name,
            signature: sig,
            body: Some(body),
        }, Span::new(s, e))
    }
};
```

- `@L` y `@R`: Capturan posiciones inicio/fin
- Arena allocation: AsignaciÃ³n eficiente de nodos
- Spans: Rastreo de ubicaciÃ³n en cÃ³digo fuente

#### 2. **Macros para ReutilizaciÃ³n**

```lalrpop
// 1+ elementos separados por coma
CommaPlus<T>: Vec<T> = {
    <v:CommaPlus<T>> "," <e:T> => { let mut v = v; v.push(e); v },
    <e:T> => vec![e],
};

// AplicaciÃ³n
IdentList: ListRef<ast::IdentName> = CommaPlus<IdentName>;
```

Esto evita duplicaciÃ³n y hace la gramÃ¡tica mÃ¡s mantenible.

#### 3. **Manejo de Precedencia de Operadores**

Go tiene 6 niveles de precedencia para operadores binarios:

```lalrpop
#[precedence(level="5")] // MÃ¡xima: *, /, %, <<, >>, &, &^
#[precedence(level="4")] // +, -, |, ^
#[precedence(level="3")] // ==, !=, <, <=, >, >=
#[precedence(level="2")] // &&
#[precedence(level="1")] // || (MÃ­nima)
```

LALRPOP genera automÃ¡ticamente la lÃ³gica para resolver conflictos shift/reduce.

#### 4. **Error Recovery**

El parser puede recuperarse de errores sintÃ¡cticos y continuar parseando:

```lalrpop
TopLevelDecl: ast::TopLevelDecl = {
    <d:Declaration> => ast::TopLevelDecl::Decl(d),
    <f:FuncDecl> => ast::TopLevelDecl::Func(f),
    <e:!> => {  // Recovery point
        errors.push(e);
        let id = arena.decls.alloc(ast::Decl::Bad, span);
        ast::TopLevelDecl::Decl(id)
    }
};
```

#### 5. **GramÃ¡tica Context-Free**

La gramÃ¡tica de Go es **context-free** (CF), lo que permite parsing eficiente con LR(1). Sin embargo, hay algunas ambigÃ¼edades sintÃ¡cticas que requieren resoluciÃ³n:

**Problema de `<-chan` vs `chan<-`:**

```go
<-chan int  // Receive-only channel
chan<- int  // Send-only channel
chan int    // Bidirectional channel
```

SoluciÃ³n: Reglas gramaticales especializadas:

```lalrpop
ChanType: ast::TypeId = {
    "<-" "chan" <t:Type> => ast::Type::Chan { dir: Recv, ... },
    "chan" "<-" <t:Type> => ast::Type::Chan { dir: Send, ... },
    "chan" <t:Type> => ast::Type::Chan { dir: Both, ... },
};
```

---

## Ãrbol de Sintaxis Abstracta (AST)

**Archivo**: [`crates/parser/src/ast.rs`](crates/parser/src/ast.rs)

### DescripciÃ³n

El AST es la representaciÃ³n intermedia del programa que captura su estructura semÃ¡ntica. EstÃ¡ diseÃ±ado para ser eficiente en memoria y tiempo de acceso.

### DiseÃ±o de Arquitectura

#### 1. **Arena Allocation**

En lugar de usar `Box<T>` o `Rc<T>`, todos los nodos se almacenan en arenas tipadas:

```rust
pub struct AstArena {
    pub decls: SpannedArena<Decl>,
    pub types: SpannedArena<Type>,
    pub exprs: SpannedArena<Expr>,
    pub stmts: SpannedArena<Stmt>,
    pub funcs: SpannedArena<FuncDecl>,
    // ...
}
```

**Ventajas**:
- Localidad de cachÃ©: nodos del mismo tipo estÃ¡n contiguos en memoria
- No hay fragmentaciÃ³n del heap
- LiberaciÃ³n en batch: `Drop` de la arena libera todo
- Sin conteo de referencias (no overhead de `Rc`/`Arc`)

#### 2. **Referencias Tipadas**

En lugar de Ã­ndices crudos (`usize`), usamos tipos wrapper:

```rust
#[repr(transparent)]
pub struct Id<T> {
    raw: u32,
    _marker: PhantomData<fn() -> T>,
}

pub type TypeId = Id<Type>;
pub type ExprId = Id<Expr>;
```

**Beneficios**:
- Type safety: no puedes usar un `TypeId` donde se espera un `ExprId`
- TamaÃ±o: `u32` permite hasta 4 billones de nodos por tipo
- Zero-cost: `#[repr(transparent)]` garantiza misma representaciÃ³n que `u32`

#### 3. **Listas Centralizadas**

En lugar de `Vec<T>` por nodo, hay buffers compartidos:

```rust
pub struct ListRef<T> {
    start: u32,
    len: u32,
    _marker: PhantomData<fn() -> T>,
}

// En AstArena:
pub struct AstExtras {
    expr_buf: Vec<ExprId>,
    type_buf: Vec<TypeId>,
    // ...
}
```

Esto evita el overhead de `Vec` (3 words) en cada nodo.

#### 4. **Side Tables para Spans**

Los spans estÃ¡n separados de los nodos:

```rust
pub struct SpannedArena<T> {
    nodes: Vec<T>,
    spans: Vec<Span>,
}
```

Esto permite:
- Recorrer nodos sin cargar informaciÃ³n de posiciÃ³n
- Compactar spans si no se necesitan despuÃ©s del parsing
- Mantener los nodos mÃ¡s pequeÃ±os

#### 5. **Symbol Interning**

Los identificadores se internan en una tabla:

```rust
pub struct Interner {
    map: HashMap<&'static str, Symbol>,
    strings: Vec<String>,
}

pub struct Symbol(u32);
pub type Ident = Symbol;
```

**Ventajas**:
- ComparaciÃ³n O(1): sÃ­mbolos son enteros
- DeduplicaciÃ³n: `package` aparece una vez en memoria
- TamaÃ±o: `Symbol` es 4 bytes vs `String` (24 bytes)

### Nodos Principales del AST

#### Declaraciones (`Decl`)

```rust
pub enum Decl {
    Bad,                    // Error recovery
    Gen(GenDecl),          // const, var, type, import
}

pub struct GenDecl {
    kind: GenDeclKind,     // Const | Var | Type | Import
    specs: ListRef<Spec>,  // Lista de especificaciones
    // ...
}
```

#### Tipos (`Type`)

```rust
pub enum Type {
    Named { ... },         // pkg.Name[Args]
    Pointer { ... },       // *T
    Array { ... },         // [N]T
    Slice { ... },         // []T
    Map { ... },           // map[K]V
    Chan { ... },          // chan T, <-chan T, chan<- T
    Struct { ... },        // struct { ... }
    Interface { ... },     // interface { ... }
    Func { ... },          // func(...) ...
    Paren { ... },         // (T)
    Bad(Span),
}
```

#### Expresiones (`Expr`)

```rust
pub enum Expr {
    Ident(Ident, Span),
    BasicLit(BasicLit),
    CompositeLit { ... },
    FuncLit { ... },
    Unary { op: UnaryOp, expr: ExprId },
    Binary { lhs: ExprId, op: BinaryOp, rhs: ExprId },
    Call { ... },
    Index { ... },
    Slice { ... },
    TypeAssert { ... },
    Paren { ... },
    Bad(Span),
}
```

#### Sentencias (`Stmt`)

```rust
pub enum Stmt {
    Bad(Span),
    Decl { decl: DeclId },
    Labeled { ... },
    Expr { expr: ExprId },
    Send { ... },
    IncDec { ... },
    Assign { ... },
    ShortVarDecl { ... },
    Go { ... },
    Defer { ... },
    Return { ... },
    Branch { ... },          // break, continue, goto, fallthrough
    Block { ... },
    If { ... },
    Switch { ... },
    TypeSwitch { ... },
    For { ... },
    Range { ... },
    Select { ... },
}
```

### Pattern: Walk Trait

Para recorrer el AST, se usa el patrÃ³n Visitor:

```rust
pub trait Walk {
    fn walk<V: Visitor>(&self, visitor: &mut V, arena: &AstArena);
}

// Generado automÃ¡ticamente con #[derive(WalkAst)]
impl Walk for Type { ... }
```

**Archivo**: [`crates/parser/src/walk.rs`](crates/parser/src/walk.rs)

---

## EspecificaciÃ³n Go 1.25

### Conformidad con la EspecificaciÃ³n

Este parser implementa la especificaciÃ³n oficial de Go 1.25 (agosto de 2025) segÃºn:

**Referencia**: [https://go.dev/ref/spec](https://go.dev/ref/spec)

### Cambios en Go 1.25

Go 1.25 mantiene **estabilidad sintÃ¡ctica total** respecto a Go 1.24. Los cambios principales fueron:

1. **EliminaciÃ³n conceptual de "Core Types"**: Se simplificÃ³ la definiciÃ³n abstracta en la especificaciÃ³n, pero la sintaxis no cambiÃ³.

2. **MaduraciÃ³n de Generic Type Aliases**: Los aliases genÃ©ricos introducidos en Go 1.23 se consideran estables.

```go
type MyMap[K comparable, V any] = map[K]V
type Vector[T any] = []T
```

3. **Restricciones de Interfaces**: Las interfaces pueden contener:
   - MÃ©todos: `Write([]byte) (int, error)`
   - Tipos embebidos: `io.Reader`
   - Uniones de tipos: `int | float64`
   - Tipos aproximados: `~string`

### GramÃ¡tica EBNF

La gramÃ¡tica completa estÃ¡ en [`crates/parser/docs/grammar.txt`](crates/parser/docs/grammar.txt).

**NotaciÃ³n**:
```ebnf
|   alternativa
()  agrupaciÃ³n
[]  opcional (0 o 1)
{}  repeticiÃ³n (0 o mÃ¡s)
```

---

## SÃ­mbolos No Terminales Soportados

A continuaciÃ³n se listan los **sÃ­mbolos no terminales** de la especificaciÃ³n Go 1.25 y su estado de soporte en este parser:

### âœ… Completamente Soportados

#### Estructura de Archivo

| SÃ­mbolo | ProducciÃ³n LALRPOP | Estado |
|---------|-------------------|--------|
| `SourceFile` | `pub SourceFile` | âœ… |
| `PackageClause` | Incorporado en `SourceFile` | âœ… |
| `ImportDecl` | `ImportDecl` | âœ… |
| `ImportSpec` | `ImportSpec` | âœ… |
| `ImportPath` | `StringLit` | âœ… |
| `TopLevelDecl` | `TopLevelDecl` | âœ… |

#### Declaraciones

| SÃ­mbolo | ProducciÃ³n LALRPOP | Estado |
|---------|-------------------|--------|
| `Declaration` | `Declaration` | âœ… |
| `ConstDecl` | `ConstDecl` | âœ… |
| `ConstSpec` | `ConstSpec` | âœ… |
| `TypeDecl` | `TypeDecl` | âœ… |
| `TypeSpec` | `TypeSpec` | âœ… |
| `AliasDecl` | Combinado en `TypeSpec` | âœ… |
| `TypeDef` | Combinado en `TypeSpec` | âœ… |
| `VarDecl` | `VarDecl` | âœ… |
| `VarSpec` | `VarSpec` | âœ… |
| `FunctionDecl` | `FuncDecl` | âœ… |
| `MethodDecl` | `FuncDecl` con `Receiver` | âœ… |

#### Tipos

| SÃ­mbolo | ProducciÃ³n LALRPOP | Estado |
|---------|-------------------|--------|
| `Type` | `Type` | âœ… |
| `TypeName` | `NamedType` | âœ… |
| `TypeLit` | `TypeLit` | âœ… |
| `TypeParameters` | `TypeParameters` | âœ… |
| `TypeParamList` | Macro `CommaTrail1<TypeParamDecl>` | âœ… |
| `TypeParamDecl` | `TypeParamDecl` | âœ… |
| `TypeConstraint` | Integrado en `TypeParamDecl` | âœ… |
| `TypeArgs` | Parte de `NamedType` | âœ… |
| `ArrayType` | `ArrayType` | âœ… |
| `SliceType` | `SliceType` | âœ… |
| `StructType` | `StructType` | âœ… |
| `PointerType` | `PointerType` | âœ… |
| `FunctionType` | `FunctionType` | âœ… |
| `InterfaceType` | `InterfaceType` | âœ… |
| `MapType` | `MapType` | âœ… |
| `ChannelType` | `ChanType` | âœ… |

#### Tipos de Interface

| SÃ­mbolo | ProducciÃ³n LALRPOP | Estado |
|---------|-------------------|--------|
| `InterfaceElem` | `InterfaceElem` | âœ… |
| `MethodSpec` | Variante de `InterfaceElem` | âœ… |
| `TypeElem` | `TypeElem` | âœ… |
| `TypeTerm` | `TypeTerm` | âœ… |
| `UnderlyingType` | Variante `TypeTerm::Tilde` | âœ… |

#### Funciones y Firmas

| SÃ­mbolo | ProducciÃ³n LALRPOP | Estado |
|---------|-------------------|--------|
| `Signature` | `Signature` | âœ… |
| `Parameters` | `Parameters` | âœ… |
| `ParameterList` | Macro `CommaOpt<ParameterDecl>` | âœ… |
| `ParameterDecl` | `ParameterDecl` | âœ… |
| `Result` | `Result` | âœ… |
| `Receiver` | `Receiver` | âœ… |

#### Sentencias BÃ¡sicas

| SÃ­mbolo | ProducciÃ³n LALRPOP | Estado |
|---------|-------------------|--------|
| `Block` | `Block` | âœ… |
| `Statement` | `Stmt` | âš ï¸ Parcial |
| `SimpleStmt` | âš ï¸ | âš ï¸ En desarrollo |
| `ReturnStmt` | `ReturnStmt` | âœ… |

### âš ï¸ Parcialmente Soportados

Estos sÃ­mbolos tienen soporte bÃ¡sico pero no todas las variantes:

| SÃ­mbolo | Estado | Faltante |
|---------|--------|----------|
| `Statement` | âš ï¸ | `IfStmt`, `ForStmt`, `SwitchStmt`, `SelectStmt` |
| `Expression` | âš ï¸ | Solo `Ident` y `BasicLit` literales |
| `PrimaryExpr` | âš ï¸ | Faltan selectores, Ã­ndices, slices, type assertions, llamadas |
| `UnaryExpr` | âŒ | No implementado |
| `BinaryExpr` | âŒ | No implementado |

### âŒ No Soportados (Pendientes)

Estos sÃ­mbolos estÃ¡n en la especificaciÃ³n pero no implementados aÃºn:

#### Sentencias de Control

- `IfStmt`
- `SwitchStmt` (Expression Switch)
- `TypeSwitchStmt`
- `ForStmt`
- `RangeClause`
- `SelectStmt`
- `GoStmt`
- `DeferStmt`
- `LabeledStmt`
- `GotoStmt`
- `BreakStmt`
- `ContinueStmt`
- `FallthroughStmt`

#### Expresiones

- `PrimaryExpr` completo:
  - `Selector` (`.field`)
  - `Index` (`[i]`)
  - `Slice` (`[low:high]`)
  - `TypeAssertion` (`.(Type)`)
  - `Arguments` (llamadas a funciones)
- `UnaryExpr` (operadores unarios: `+`, `-`, `!`, `^`, `*`, `&`, `<-`)
- `BinaryExpr` (operadores binarios: `+`, `-`, `*`, `/`, `%`, `&`, `|`, `^`, `<<`, `>>`, `&^`, `&&`, `||`, `==`, `!=`, `<`, `<=`, `>`, `>=`)
- `Conversion` (`Type(expr)`)
- `CompositeLit` (literales compuestos)
- `FunctionLit` (funciones anÃ³nimas)

#### Otros

- `Assignment` completo (solo bÃ¡sico)
- `ShortVarDecl` (`:=`)
- `IncDecStmt` (`++`, `--`)
- `SendStmt` (`<-`)

---

## SÃ­mbolos Terminales Soportados

### Tokens LÃ©xicos

El lexer reconoce **todos** los tokens de la especificaciÃ³n Go 1.25:

#### Keywords (25)

```rust
pub enum Tok<'input> {
    // Control de flujo
    KwBreak, KwCase, KwContinue, KwDefault, KwFallthrough,
    KwFor, KwGoto, KwIf, KwElse, KwSwitch, KwSelect,
    
    // Declaraciones
    KwConst, KwFunc, KwImport, KwPackage, KwType, KwVar,
    
    // Tipos
    KwChan, KwInterface, KwMap, KwStruct,
    
    // Concurrencia
    KwGo, KwDefer,
    
    // IteraciÃ³n
    KwRange,
    
    // Control de funciones
    KwReturn,
}
```

#### Literales

```rust
Ident(&'input str),        // identificadores: foo, _bar, utf8_Î±Î²Î³
IntLit(&'input str),       // 42, 0x2A, 0o52, 0b101010, 1_000_000
FloatLit(&'input str),     // 3.14, 1e10, 0x1.8p3
ImagLit(&'input str),      // 3.14i, 1e10i
RuneLit(&'input str),      // 'a', '\n', '\u0041'
StringLit(&'input str),    // "hello\n"
RawStringLit(&'input str), // `raw\nstring`
```

#### Operadores y PuntuaciÃ³n (58 tokens)

##### Operadores AritmÃ©ticos
- `Plus` (`+`), `Minus` (`-`), `Star` (`*`), `Slash` (`/`), `Percent` (`%`)

##### Operadores Bitwise
- `Amp` (`&`), `Pipe` (`|`), `Caret` (`^`), `Tilde` (`~`)
- `Shl` (`<<`), `Shr` (`>>`), `AndNot` (`&^`)

##### Operadores LÃ³gicos
- `LAnd` (`&&`), `LOr` (`||`), `Bang` (`!`)

##### Operadores de ComparaciÃ³n
- `EqEq` (`==`), `NotEq` (`!=`)
- `Lt` (`<`), `Le` (`<=`), `Gt` (`>`), `Ge` (`>=`)

##### Operadores de AsignaciÃ³n
- `Assign` (`=`), `Define` (`:=`)
- `AddAssign` (`+=`), `SubAssign` (`-=`), `MulAssign` (`*=`)
- `DivAssign` (`/=`), `ModAssign` (`%=`)
- `AndAssign` (`&=`), `OrAssign` (`|=`), `XorAssign` (`^=`)
- `ShlAssign` (`<<=`), `ShrAssign` (`>>=`), `AndNotAssign` (`&^=`)

##### Operadores de Incremento/Decremento
- `Inc` (`++`), `Dec` (`--`)

##### Operadores de Canales
- `Arrow` (`<-`)

##### PuntuaciÃ³n
- `LParen` (`(`), `RParen` (`)`)
- `LBrack` (`[`), `RBrack` (`]`)
- `LBrace` (`{`), `RBrace` (`}`)
- `Comma` (`,`), `Semi` (`;`), `Colon` (`:`)
- `Dot` (`.`), `Ellipsis` (`...`)

##### Especiales
- `Underscore` (`_`)
- `Error` (token de error para recovery)

---

## Dependencias

El proyecto usa un conjunto mÃ­nimo de dependencias de alta calidad:

### Dependencias de ProducciÃ³n

```toml
[dependencies]
logos = "0.16.0"           # Lexer generator (DFA-based)
thiserror = "2.0.17"       # Error handling macros
smallvec = "1.15.1"        # Stack-allocated vectors
memchr = "2.7.6"           # Optimized string searching
lalrpop-util = "0.22.2"    # Runtime support for LALRPOP
```

#### **Logos** (`0.16.0`)
- **PropÃ³sito**: GeneraciÃ³n de lexers de alto rendimiento
- **TecnologÃ­a**: Genera cÃ³digo Rust con DFAs (Deterministic Finite Automata)
- **Ventajas**: 
  - Zero-cost abstractions
  - Sin dependencias de runtime
  - Performance comparable a lexers escritos a mano

#### **LALRPOP** (`0.22.2`)
- **PropÃ³sito**: GeneraciÃ³n de parsers LR(1)
- **TecnologÃ­a**: Genera tablas de parsing en tiempo de compilaciÃ³n
- **Ventajas**:
  - Parser determinista y eficiente
  - Manejo automÃ¡tico de precedencia
  - Mensajes de error de conflictos LR

#### **Thiserror** (`2.0.17`)
- **PropÃ³sito**: DerivaciÃ³n automÃ¡tica de traits `Error` y `Display`
- **Uso**: Tipos de error estructurados (`LexErrorKind`, `ParseError`)

#### **SmallVec** (`1.15.1`)
- **PropÃ³sito**: Vectores optimizados para casos pequeÃ±os
- **Uso**: Listas temporales durante parsing
- **Ventaja**: Evita heap allocation para N â‰¤ capacidad inline

#### **Memchr** (`2.7.6`)
- **PropÃ³sito**: BÃºsqueda optimizada de bytes/caracteres
- **Uso**: Escaneo de comentarios de bloque (`*/`), strings raw (`` ` ``)
- **Ventaja**: Usa instrucciones SIMD cuando estÃ¡ disponible

### Dependencias de Build

```toml
[build-dependencies]
lalrpop = "0.22.2"         # Parser generator
gag = "1"                  # Silencia output de LALRPOP
```

### Dependencias de Desarrollo

```toml
[dev-dependencies]
proptest = "1"             # Property-based testing
pretty_assertions = "1"    # Asserts con mejor output
walkdir = "2"              # Traversal de directorios
criterion = "0.8.1"        # Benchmarking framework
```

#### **Proptest** (`1`)
- **PropÃ³sito**: Testing basado en propiedades
- **Uso**: Fuzzing del lexer con inputs aleatorios
- **Ventaja**: Descubre edge cases automÃ¡ticamente

#### **Criterion** (`0.8.1`)
- **PropÃ³sito**: Benchmarking estadÃ­sticamente riguroso
- **CaracterÃ­sticas**:
  - DetecciÃ³n de regresiones de performance
  - GrÃ¡ficos HTML
  - Comparaciones entre ejecuciones

---

## Uso

### InstalaciÃ³n

```bash
# Clonar el repositorio
git clone https://github.com/usuario/go125_parser.git
cd go125_parser

# Compilar (genera el parser LALRPOP)
cargo build --release
```

### API BÃ¡sica

```rust
use go125_parser::{Lexer, parser};
use go125_parser::ast::AstArena;
use go125_parser::ast::Interner;

fn main() {
    let source = r#"
        package main
        
        import "fmt"
        
        func main() {
            return
        }
    "#;
    
    // Fase 1: Lexer
    let lexer = Lexer::new(source);
    
    // Fase 2: Parser
    let mut arena = AstArena::new();
    let mut interner = Interner::new();
    let mut errors = Vec::new();
    
    match parser::SourceFileParser::new().parse(
        &mut arena,
        &mut interner,
        &mut errors,
        lexer
    ) {
        Ok(source_file) => {
            println!("âœ… Parsing exitoso!");
            println!("Paquete: {:?}", source_file.name);
            println!("Declaraciones: {}", arena.top_decls(source_file.decls).len());
        }
        Err(e) => {
            eprintln!("âŒ Error de parsing: {:?}", e);
        }
    }
    
    // Obtener diagnÃ³sticos del lexer
    let lexer = Lexer::new(source);
    let diags = lexer.take_diags();
    for diag in diags {
        eprintln!("Lexer: {:?}", diag);
    }
}
```

### ConstrucciÃ³n Incremental

```bash
# Build optimizado
cargo build --release

# Build con sÃ­mbolos de debug (Ãºtil para profiling)
cargo build --profile=release

# Limpiar artefactos generados
cargo clean
```

El archivo `build.rs` ejecuta LALRPOP automÃ¡ticamente:

```rust
// crates/parser/build.rs
fn main() {
    lalrpop::process_root().unwrap();
}
```

Esto genera `parser.rs` a partir de `parser.lalrpop` en tiempo de compilaciÃ³n.

---

## Testing y ValidaciÃ³n

El proyecto tiene una suite completa de tests organizados por subsistema:

### Tests del Lexer

**UbicaciÃ³n**: [`crates/parser/tests/`](crates/parser/tests/)

#### 1. **Tests Golden** (`lexer_golden.rs`)
- Compara salida del lexer contra archivos `.golden`
- Verifica tokens, spans y tipos

#### 2. **Tests de NÃºmeros** (`lexer_numbers.rs`)
- Enteros: decimal, hex, octal, binario
- Flotantes: cientÃ­fica, hexadecimal
- Imaginarios: sufijo `i`
- Underscores: `1_000_000`
- **Compatibilidad**: `lexer_numbers_go_scanner.rs` valida contra el scanner de Go

#### 3. **Tests de Strings** (`lexer_strings.rs`)
- Strings interpretados con escapes: `\n`, `\t`, `\u`, `\U`, `\x`
- Raw strings: `` `...` ``
- Runes: `'a'`, `'\n'`, `'\u0041'`

#### 4. **Tests de Comentarios** (`lexer_comments_cr.rs`)
- Comentarios de lÃ­nea: `// ...`
- Comentarios de bloque: `/* ... */`
- InserciÃ³n de `;` despuÃ©s de comentarios con `\n`

#### 5. **Tests de Punto y Coma** (`lexer_semis.rs`)
- InserciÃ³n automÃ¡tica de `;` segÃºn reglas de Go
- Casos edge: `)`, `}`, `]`, keywords

#### 6. **Tests de Whitespace** (`lexer_whitespace.rs`)
- Espacios, tabs, saltos de lÃ­nea, CR+LF

#### 7. **Tests de Unicode** (`lexer_unicode.rs`)
- Identificadores Unicode: `Î±Î²Î³`, `å‡½æ•°`
- BOM (Byte Order Mark)
- Normalization

#### 8. **Tests de Errores** (`lexer_errors_corpus.rs`)
- Tokens invÃ¡lidos
- NÃºmeros malformados
- Strings sin cerrar
- Comentarios sin terminar

#### 9. **Property-Based Tests** (`lexer_props.rs`)
- Fuzzing con Proptest
- Invariantes: todo input vÃ¡lido produce tokens o errores, nunca panic

#### 10. **Scan Table** (`lexer_scan_table.rs`)
- Verifica la tabla de inserciÃ³n de `;`
- Cobertura de todos los tokens

### Tests del Parser

Actualmente el parser tiene soporte bÃ¡sico. Los tests futuros incluirÃ¡n:

- **Golden tests**: Comparar AST contra archivos `.ast`
- **Roundtrip tests**: Parser â†’ AST â†’ Pretty Print â†’ Parser
- **Error recovery tests**: Validar nodos `Bad` y continuaciÃ³n de parsing
- **Corpus de Go estÃ¡ndar**: Parsear paquetes de la librerÃ­a estÃ¡ndar de Go

### Benchmarks

```bash
# Ejecutar benchmarks con Criterion
cargo bench

# Ver reportes HTML
open target/criterion/report/index.html
```

Benchmarks incluyen:
- Lexer: tokens/segundo
- Parser: lÃ­neas/segundo
- Arena allocation: allocaciones/segundo

### Fuzzing

El directorio [`fuzz/`](fuzz/) contiene targets de fuzzing:

```bash
# Instalar cargo-fuzz
cargo install cargo-fuzz

# Ejecutar fuzzer del lexer
cargo fuzz run lexer

# Ver crashes
cargo fuzz cov lexer
```

---

## Arquitectura de MÃ³dulos

```
go125_parser/
â”œâ”€â”€ crates/
â”‚   â”œâ”€â”€ parser/              # Parser principal
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ lib.rs       # Re-exports pÃºblicos
â”‚   â”‚   â”‚   â”œâ”€â”€ lexer.rs     # Lexer (Logos)
â”‚   â”‚   â”‚   â”œâ”€â”€ parser.lalrpop   # GramÃ¡tica LALRPOP
â”‚   â”‚   â”‚   â”œâ”€â”€ parser.rs    # (Generado por LALRPOP)
â”‚   â”‚   â”‚   â”œâ”€â”€ ast.rs       # AST y arenas
â”‚   â”‚   â”‚   â”œâ”€â”€ error.rs     # Tipos de error
â”‚   â”‚   â”‚   â”œâ”€â”€ walk.rs      # Visitor pattern
â”‚   â”‚   â”‚   â””â”€â”€ parser_support.rs  # Helpers
â”‚   â”‚   â”œâ”€â”€ build.rs         # Build script (LALRPOP)
â”‚   â”‚   â”œâ”€â”€ tests/           # Suite de tests
â”‚   â”‚   â””â”€â”€ docs/            # DocumentaciÃ³n de gramÃ¡tica
â”‚   â”‚
â”‚   â””â”€â”€ ast_derive/          # Proc macro para #[derive(WalkAst)]
â”‚       â””â”€â”€ src/
â”‚           â””â”€â”€ lib.rs
â”‚
â”œâ”€â”€ fuzz/                    # Fuzzing targets
â”‚   â””â”€â”€ fuzz_targets/
â”‚       â””â”€â”€ lexer.rs
â”‚
â””â”€â”€ Cargo.toml               # Workspace config
```

---

## Roadmap

### Fase 1: Lexer âœ… (Completado)
- [x] TokenizaciÃ³n completa
- [x] InserciÃ³n de `;`
- [x] Manejo de comentarios
- [x] Literales (nÃºmeros, strings, runes)
- [x] Tests exhaustivos

### Fase 2: Parser BÃ¡sico âœ… (Completado)
- [x] Estructura de archivo (`SourceFile`)
- [x] Declaraciones: `const`, `var`, `type`, `import`, `func`
- [x] Tipos: primitivos, structs, interfaces, maps, channels, arrays, slices
- [x] GenÃ©ricos: type parameters, type arguments
- [x] FunciÃ³n bÃ¡sica con `return`

### Fase 3: Expresiones (En Progreso ğŸš§)
- [ ] Literales bÃ¡sicos
- [ ] Operadores unarios y binarios
- [ ] Llamadas a funciones
- [ ] Ãndices y slices
- [ ] Type assertions
- [ ] Composite literals
- [ ] Funciones anÃ³nimas

### Fase 4: Sentencias de Control (Pendiente)
- [ ] `if`/`else`
- [ ] `for` (clÃ¡sico y `range`)
- [ ] `switch` (expression y type)
- [ ] `select`
- [ ] `go` y `defer`
- [ ] Labels y `goto`

### Fase 5: ValidaciÃ³n SemÃ¡ntica (Futuro)
- [ ] Symbol table
- [ ] Type checking
- [ ] Scoping rules
- [ ] Constant evaluation
- [ ] Initialization order

---

## Contribuir

Contribuciones son bienvenidas! Ãreas de alto impacto:

1. **Implementar expresiones** (`Expr` en `parser.lalrpop`)
2. **Implementar sentencias de control** (`IfStmt`, `ForStmt`, etc.)
3. **Agregar mÃ¡s tests** (especialmente golden tests con cÃ³digo Go real)
4. **OptimizaciÃ³n**: mejorar performance del lexer o arena allocation
5. **DocumentaciÃ³n**: ejemplos de uso, tutoriales

### Estilo de CÃ³digo

- Seguir convenciones de Rust: `cargo fmt`, `cargo clippy`
- Documentar funciones pÃºblicas con `///`
- Tests unitarios para cada feature
- Mantener terminologÃ­a de compiladores consistente

---

## Licencia

MIT OR Apache-2.0 (dual license)

---

## Referencias

### EspecificaciÃ³n de Go
- [The Go Programming Language Specification](https://go.dev/ref/spec)
- [Go 1.25 Release Notes](https://go.dev/doc/go1.25)

### Herramientas
- [Logos Documentation](https://docs.rs/logos/)
- [LALRPOP Book](https://lalrpop.github.io/lalrpop/)
- [Rust API Guidelines](https://rust-lang.github.io/api-guidelines/)

### TeorÃ­a de Compiladores
- *Compilers: Principles, Techniques, and Tools* (Dragon Book)
- *Engineering a Compiler* (Cooper & Torczon)
- *Modern Compiler Implementation in ML* (Appel)

---

## Contacto

Para preguntas o discusiones tÃ©cnicas, abrir un issue en GitHub.

---

**Ãšltima actualizaciÃ³n**: Enero 2026  
**VersiÃ³n del parser**: 0.1.0  
**Compatibilidad**: Go 1.25 (spec de agosto 2025)
